# Day 10
### 27 July, 2018

1. Revised Matplotlib, Seaborn and Linear Regression

2. Cross Validation and Bias trade-off  
  This bias variance trade-off is the point where we are adding just noise by adding model complexity.   
  The model after the bias variance trade-off begins to overfit.

3. Logistic Regression
  * Logistic Regression as a method for classification
  * Suitable for binary class classification
  * Logistic Regression curve can only go between 0 and 1
  * Sigmoid (aka Logistic) Function
    * Takes in any value and outputs it between 0 and 1
  * Based off the probability from the logistic function, we assign a class
    * [0, 0.5]: Class 0
    * (0.5, 1]: Class 1
  * Confusion matrix is a table used to describe the performance of a classification model.
    * True Positive (TP)
    * True Negative (TN)
    * False Positive (FP)
    * False Negative (FN)
  * Accuracy = (TP + TN) / (TP + TN + FP + FN)
  * Error Rate = (FP + FN) / (TP + TN + FP + FN)
  * Type 1 error and Type 2 error